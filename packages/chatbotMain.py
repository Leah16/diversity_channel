import streamlit as st  # å¯¼å…¥Streamlitåº“ç”¨äºåˆ›å»ºWebç•Œé¢
from typing import List, Dict  # å¯¼å…¥ç±»å‹æç¤º
from packages.chatbotengine import ChatbotEngine  # å¯¼å…¥è‡ªå®šä¹‰çš„èŠå¤©å¼•æ“æ¨¡å—
from packages.ttsengine import TTSEngine  # å¯¼å…¥TTSå¼•æ“
import os

def chatbotMain():
    # åˆå§‹åŒ–TTSå¼•æ“
    if "tts_engine" not in st.session_state:
        st.session_state.tts_engine = TTSEngine()
    
    # å¦‚æœèŠå¤©å¼•æ“ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹
    if "chat_engine" not in st.session_state:
        st.session_state.chat_engine = ChatbotEngine()
    
    # åˆå§‹åŒ–æ¶ˆæ¯å†å²åˆ—è¡¨
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # åˆ›å»ºæ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
    available_models = ChatbotEngine.get_available_models()
    selected_model = st.selectbox("Select a model", available_models)
    
    # éå†å¹¶æ˜¾ç¤ºæ‰€æœ‰å†å²æ¶ˆæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # åˆ›å»ºç”¨æˆ·è¾“å…¥æ¡†å¹¶å¤„ç†è¾“å…¥
    if prompt := st.chat_input("Your question"):
        
        # å¦‚æœæœ‰æ–°å¯¹è¯ï¼Œæ¸…é™¤ä¹‹å‰çš„éŸ³é¢‘
        if "last_audio" in st.session_state:
            del st.session_state.last_audio
        
        # åˆå§‹åŒ–RAGä¸Šä¸‹æ–‡
        context = ""
        if "rag_module" in st.session_state and st.session_state.rag_module.vector_store:
            context = st.session_state.rag_module.get_context(prompt)
            
        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        # å¤„ç†åŠ©æ‰‹å“åº”
        with st.chat_message("assistant"):
            message_placeholder = st.empty()  # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼æ˜¾ç¤º
            full_response = ""  # å­˜å‚¨å®Œæ•´å“åº”
            
            # æµå¼æ¥æ”¶å¹¶æ˜¾ç¤ºAIå“åº”
            for response_chunk in st.session_state.chat_engine.query_ollama(
                prompt, 
                selected_model,
                context=context if "rag_module" in st.session_state and st.session_state.rag_module.vector_store else ""
            ):
                full_response += response_chunk
                message_placeholder.write(full_response + "â–Œ")  # æ˜¾ç¤ºæ‰“å­—æ•ˆæœ
            
            message_placeholder.write(full_response)  # æ˜¾ç¤ºæœ€ç»ˆå®Œæ•´å“åº”
            
            # å°†åŠ©æ‰‹å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    
    # åˆ›å»ºä¸€ä¸ªè¡Œæ¥æ”¾ç½®æŒ‰é’®å’ŒéŸ³é¢‘æ’­æ”¾å™¨
    col1, col2, col3 = st.columns(3)
    
    # æ¸…é™¤å†å²æŒ‰é’®
    with col1:
        if st.button("Clear chat history"):
            st.session_state.messages = []  # æ¸…ç©ºæ¶ˆæ¯å†å²
            st.rerun()  # é‡æ–°åŠ è½½é¡µé¢
    
    # éŸ³é¢‘ç”ŸæˆæŒ‰é’®
    with col2:
        # åªæœ‰åœ¨æœ‰æ¶ˆæ¯å†å²ä¸”æœ€åä¸€æ¡æ˜¯åŠ©æ‰‹æ¶ˆæ¯æ—¶æ‰å¯ç”¨æŒ‰é’®
        last_message = st.session_state.messages[-1] if st.session_state.messages else None
        can_play = last_message and last_message["role"] == "assistant"
        
        # ç”ŸæˆéŸ³é¢‘æŒ‰é’®
        if st.button("ğŸ”Š Generate audio", disabled=not can_play):
            try:
                audio_file = st.session_state.tts_engine.generate_speech(last_message["content"])
                st.session_state.last_audio = audio_file
                st.session_state.last_audio_text = last_message["content"]  # ä¿å­˜å¯¹åº”çš„æ–‡æœ¬
                st.rerun()
            except Exception as e:
                st.error(f"Failed to generate audio: {str(e)}")
    
    # éŸ³é¢‘æ’­æ”¾å™¨
    with col3:
        if ("last_audio" in st.session_state and 
            os.path.exists(st.session_state.last_audio) and 
            st.session_state.messages and 
            st.session_state.messages[-1]["content"] == st.session_state.last_audio_text):
            st.audio(st.session_state.last_audio)
    

if __name__ == "__main__":
    chatbotMain()  # ç¨‹åºå…¥å£ç‚¹